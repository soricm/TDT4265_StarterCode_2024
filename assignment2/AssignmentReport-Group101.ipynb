{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marijan Soric and Zan Stanonik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Backpropagation:\n",
    "$$w_{ji} := w_{ji} − \\alpha \\frac{\\partial C}{\\partial w_{ji}}$$\n",
    "With the chain rule:\n",
    "$$\\frac{\\partial C}{\\partial w_{ji}}=\\frac{\\partial C}{\\partial z_j}\\frac{\\partial z_j}{\\partial w_{ji}}=\\delta_j \\frac{\\partial }{\\partial w_{ji}} \\left(\\sum_i w_{ij}x_i \\right)=\\delta_j x_i$$\n",
    "With $$\\delta_j=\\frac{\\partial C}{\\partial z_j}=−(y_j − \\hat{y}_j)=−(y_j − f(z_j))$$\n",
    "But also:\n",
    "$$\\delta_j=\\frac{\\partial C}{\\partial z_j}= \\frac{\\partial C}{\\partial a_j}\\frac{\\partial a_j}{\\partial z_j}$$\n",
    "$$\\frac{\\partial C}{\\partial a_j}=\\sum_k \\underbrace{\\frac{\\partial C}{\\partial z_k}}_{\\delta_k}\\underbrace{\\frac{\\partial z_k}{\\partial a_j}}_{w_{kj}}=\\sum_k \\delta_k w_{kj}$$\n",
    "And, as activation function the sigmoid,\n",
    "$$\\frac{\\partial a_j}{\\partial z_j}=\\frac{\\partial f(z_j)}{\\partial z_j}=f'(z_j)$$\n",
    "Thus we obtain:\n",
    "$$\\delta_j=f'(z_j)\\sum_k \\delta_k w_{kj}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Vectorize computation:\n",
    "Input into hidden layer:\n",
    "$$W^{(0)} \\leftarrow W^{(0)} − \\alpha f'(Z) \\odot (W^{(0)T} (\\hat Y - Y)) \\cdot X^T$$\n",
    "Where $W^{(0)} \\in \\mathbb R^{J \\times I}, Z \\in \\mathbb R^{J \\times N}, Y \\in \\mathbb R^{N \\times J}, X \\in \\mathbb R^{N \\times I}$\n",
    "\n",
    "Hidden layer into output layer:\n",
    "$$W^{(1)} \\leftarrow W^{(1)} − \\alpha  (\\hat Y - Y) \\cdot H^T$$\n",
    "\n",
    "Where $W^{(1)} \\in \\mathbb R^{K \\times J}, Y \\in \\mathbb R^{K \\times N}, H \\in \\mathbb R^{N \\times J}$\n",
    "\n",
    "Where $\\cdot$ is the matrix multiplication and $\\odot$ the Hadamard product (pointwise multiplication). And \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: X: (20000, 784), Y: (20000, 1)\n",
      "Validation shape: X: (10000, 784), Y: (10000, 1)\n",
      "Mean: 33.55\n",
      "Standard deviation: 78.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "X, Y_train, *_ = utils.load_full_mnist()\n",
    "print(f\"Mean: {np.mean(X):.2f}\\nStandard deviation: {np.var(X)**.5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![task2c_train_loss.png](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "There are $785 \\times 64 + 64 \\times 10 = 50 880$ parameters in the nework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortly comment on the change in performance, which has hopefully improved with each addition, at least in terms of learning speed. Note that we expect you to comment on convergence speed, generalization/overfitting, and final accuracy/validation loss of the model. Include a plot of the loss detailing the improvements for each addition. We’ve included task3.py as an example on how you can create this comparison plot. You can extend this file to solve this task.*\n",
    "\n",
    "We add more more _improvement_ at each step. The result doen't look good...\n",
    "## a) use_improved_sigmoid\n",
    "![task3c_train_loss_use_improved_sigmoid.png](task3c_train_loss_use_improved_sigmoid.png) \n",
    "\n",
    "\n",
    "Improving the activation function help to reduced vanishing gradient problem.\n",
    "## b)  use_improved_weight_init\n",
    "![task3c_train_loss_use_improved_weight_init.png](task3c_train_loss_use_improved_weight_init.png)\n",
    "\n",
    "\n",
    "Faster convergence.\n",
    "## c) momentum_gamma\n",
    "![task3c_train_loss_use_momentum.png](task3c_train_loss_use_momentum.png)\n",
    "\n",
    "Faster convergence and improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "*Set the number of hidden units to 32. What do you observe if the number of hidden\n",
    "units is too small?*\n",
    "\n",
    "If the number of hidden units is too small, $785 \\times 32 + 32 \\times 10 =25 440$ (we have half as many parameters as before), the model can be too \"simple\" and fail to fit the data (and thus generalize well). In this case it would be underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "*Set the number of hidden units to 128. What do you observe if the number is too large?*\n",
    "\n",
    "If the number of hidden units is too small, $785 \\times 128 + 128 \\times 10 =101 760$ the model can be too \"complicated\" and fail to generalize well the data. In this case it would be overfitting.\n",
    "\n",
    "So the number of units in the hidden layer is an hyperparameter that should be well choosen regarding the trade off bias variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "FILL IN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
