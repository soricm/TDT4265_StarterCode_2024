{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marijan Soric and Zan Stanonik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "$$I =  \\begin{pmatrix}\n",
    "    2& 1& 2& 3& 1 \\\\\n",
    "    3& 9& 1& 1& 4 \\\\\n",
    "    4& 5& 0& 7& 0\n",
    "  \\end{pmatrix}\n",
    "\\quad\n",
    "K = \\begin{pmatrix}\n",
    "    -1 & 0 & 1 \\\\\n",
    "    -2 & 0 & 2 \\\\\n",
    "    -1 & 0 & 1\n",
    "  \\end{pmatrix}$$\n",
    "  \n",
    "$$K \\star I \\in \\mathbb R^{3\\times 5}$$\n",
    "$$K \\star I = \\scriptsize{\\begin{pmatrix}\n",
    "    1 \\cdot 2 +9 \\cdot 1 &2\\cdot (-2) + 3\\cdot (-1) +2\\cdot 2 + 1\\cdot 1 & 1\\cdot (-2) + 9\\cdot (-1)  +3\\cdot 2 +1 \\cdot 1& 2\\cdot (-2) + 1\\cdot (-1) +1\\cdot 2 + 4\\cdot 1& 3\\cdot (-2) + 1\\cdot (-1) \\\\\n",
    "    1 \\cdot 1 + 9 \\cdot 2 + 5 \\cdot 1& 2\\cdot (-1) +3\\cdot (-2) + 4\\cdot (-1) +2\\cdot 1 +1\\cdot 2 + 0\\cdot 1&1\\cdot (-1) +9\\cdot (-2) + 5\\cdot (-1) +3\\cdot 1 +1\\cdot 2 + 7\\cdot 1& 2\\cdot (-1) +1\\cdot (-2) +1\\cdot 1 +4\\cdot 2 & 3\\cdot (-1) +1\\cdot (-2) + 7\\cdot (-1) \\\\\n",
    "    9 \\cdot 1 + 5 \\cdot 2& 3\\cdot (-1) 4+\\cdot (-2) +1\\cdot 1 &9 \\cdot (-1) +5\\cdot (-2) +1\\cdot 1 +7\\cdot 2 & 1\\cdot (-1) + \\cdot (-1) +4\\cdot 1 &1 \\cdot (-1) +7\\cdot (-2) \n",
    "  \\end{pmatrix} }$$\n",
    "  $$I \\star K = \\begin{pmatrix}\n",
    "    -11& 2& 4& -1& 7\\\\\n",
    "    -24& 8& 12& -5& 12\\\\\n",
    "    -19& 10& 4& -3& 15\n",
    "  \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11,   2,   4,  -1,   7],\n",
       "       [-24,   8,  12,  -5,  12],\n",
       "       [-19,  10,   4,  -3,  15]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "x = np.array([[2, 1, 2, 3, 1],\n",
    "              [3, 9, 1, 1, 4],\n",
    "              [4, 5, 0, 7, 0]])\n",
    "y = np.array([[-1, 0, 1],\n",
    "              [-2, 0, 2],\n",
    "              [-1, 0, 1]])\n",
    "scipy.ndimage.convolve(x,y,mode='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "The **Max Pooling layer** reduces the sensitivity to small translational variations in the input.\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "*Given a single convolutional layer with a stride $S=1$, kernel size of 7 × 7 $F=7$, and 6 filters. If you want the output shape (Height × Width) of the convolutional layer to be equal to the input image, how much padding $P$ should you use on each side?*\n",
    "\n",
    "There are two equations that link output shape to the input shape:\n",
    "$$W_\\text{out}=\\left\\lfloor \\frac{W_\\text{in}-F+2\\mathbf{P}}{S} \\right\\rfloor+1 \\quad H_\\text{out}=\\left\\lfloor\\frac{H_\\text{in}-F+2\\mathbf{P}}{S}\\right\\rfloor+1$$\n",
    "Since, $W_\\text{out}=W_\\text{in}$ and $H_\\text{out}=H_\\text{in}$,\n",
    "$$\\left\\lfloor 2 \\mathbf{P} \\right\\rfloor=F-1=6 \\Rightarrow \\mathbf{P}=\\textbf{3}$$\n",
    "\n",
    "\n",
    "\n",
    "## task 1d)\n",
    "\n",
    "*You are told that the spatial dimensions of the feature maps in the first layer are 508 × 508\n",
    "and that there are 12 feature maps in the first layer. Assuming that no padding is used, the stride\n",
    "is 1, and the kernel used is square and odd number size, what are the spatial dimensions of these\n",
    "kernels? Give the answer as (Height) × (Width).*\n",
    "\n",
    "$$W_\\text{out}=\\frac{W_\\text{in}-\\mathbf{F}+2P}{S}+1$$\n",
    "With numerical values:\n",
    "$$508=\\frac{512-\\mathbf{F}+2 \\times 0}{1}+1$$\n",
    "$$\\mathbf{F}=512-508+1=\\textbf{5}$$\n",
    "Same result for the width. Thus the kernel is in $\\mathbb R^{5 \\times 5}$\n",
    "\n",
    "## task 1e)\n",
    "*If subsampling is done after the first convolutional layer, using filters of size 2 × 2, with a stride of 2, what are the spatial dimensions of the pooled feature maps in the first pooling layer? Give the answer as (Height) × (Width).*\n",
    "\n",
    "After the pooling with size $2 \\times 2$ and stride of 2, the spatial dimensions becomes $\\left( \\frac{508}{2},\\frac{508}{2} \\right)=\\textbf{(254,254)}$.\n",
    "\n",
    "## task 1f)\n",
    "*The spatial dimensions of the convolution kernels in the second layer are 3 × 3. Assuming no\n",
    "padding and a stride of 1, what are the sizes of the feature maps in the second layer? Give the\n",
    "answer as (Height) × (Width).*\n",
    "\n",
    "$$\\mathbf{W}_\\text{out}=\\left\\lfloor \\frac{W_\\text{in}-F+2P}{S} \\right\\rfloor+1$$\n",
    "With numerical values:\n",
    "$$\\mathbf{W}_\\text{out}=\\frac{254-3+2 \\times 0}{1}+1$$\n",
    "$$\\mathbf{W}_\\text{out}=252$$\n",
    "Same result for the width. Thus the sizes of the feature maps in the second layer are $\\textbf{(252,252)}$.\n",
    "\n",
    "\n",
    "\n",
    "## task 1g)\n",
    "Let's count how many parameters there are in the network.\n",
    "\n",
    "| Layer | Type  | Units / Filters | Input size      | Output size    | Number of parameters |Value    |\n",
    "|-------|-------|-----------------|-----------------|----------------|----------------------|---------|\n",
    "| 1     | Conv+Pool| 32           |  3x(32x32)      |32x(16x16)      | 32x(3x(5x5)+1)       |2 432    |\n",
    "| 2     | Conv+Pool| 64           | 32x(16x16)      | 64x(8x8)       | 64x(32x(5x5)+1)      |51 264   |  \n",
    "| 3     | Conv+Pool| 128          | 64x(8x8)        | 128x(4x4)      | 128x(64x(5x5)+1)     |204 928  |\n",
    "| 4     | Fully | 64              |  (128x4x3)      | 64             | 64x(128x(4x4)+1)     |131 136  |\n",
    "| 5     | Fully | 10              | 64              | 10             | 10x(64+1)            |650      |\n",
    "| *Sum* |   -   | -               |       -         |    -           |      -               |**390 410**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "![Task 2](./plots/task2_plot.png)\n",
    "\n",
    "We can notice that the training loss is decreasing, but the validation loss is stagnating and starting to increase which is a sign of overfitting.   \n",
    "  \n",
    "Validation loss is 0.83, and the validation accuracy is 71.9%.\n",
    "\n",
    "### Task 2b)\n",
    "The final losses & accuracies are the following:    \n",
    "   \n",
    "Training evaluation\n",
    "- Training Accuracy: 86.9 %\n",
    "\n",
    "--------------------------------------------------\n",
    "Validation evaluation \n",
    "- Validation Accuracy: 71.9 %\n",
    "\n",
    "--------------------------------------------------\n",
    "Test evaluation \n",
    "- Test Accuracy: 71.8 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Layer | Layer Type       | Number of Hidden Units / Number of Filters |\n",
    "|-------|------------------|-------------------------------------------|\n",
    "| 1     | Conv2D           | 32                                        |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | Conv2D           | 32                                        |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | MaxPool2D        | -                                         |\n",
    "| 2     | Conv2D           | 64                                        |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | Conv2D           | 64                                        |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | MaxPool2D        | -                                         |\n",
    "| 3     | Conv2D           | 128                                       |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | Conv2D           | 128                                       |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | MaxPool2D        | -                                         |\n",
    "| 4     | Conv2D           | 256                                       |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | Conv2D           | 256                                       |\n",
    "|       | BatchNorm2d      | -                                         |\n",
    "|       | ReLU             | -                                         |\n",
    "|       | MaxPool2D        | -                                         |\n",
    "|       | Flatten          | -                                         |\n",
    "| 5     | Fully-Connected  | 64                                        |\n",
    "|       | BatchNorm1d      | -                                         |\n",
    "| 6     | Fully-Connected  | num_classes                               |\n",
    "|       | BatchNorm1d      | -                                         |\n",
    "\n",
    "\n",
    "The network by our design hence has 6 layers, made out of 4 exactly the same block with different filter sizes. It could be argued that there are actually 10 layers, but for us one layer is conv2d-batchnorm2-relu-conv2d-batchnorm2d-relu-maxpool2d, similar to what was suggested in the instructions pdf.\n",
    "\n",
    "Optimizer used in the final model is AdaGrad, for regularization weight decay of 1e-5 in the optimizer was used. We also tested out dropout, but the results in combination with weight decay looked the same or worse so Dropout was removed.\n",
    "\n",
    "Learning rate was kept the same as before at 5e-2, same goes for batch size (64). All Linear and Conv2d units of the network were initialized with the Kaiming normal method. Apart from that, only the dataset loaders were changed so that the training loader transforms the images in the following way:\n",
    "\n",
    "| Transformation                  | Description                                           |\n",
    "|--------------------------------|-------------------------------------------------------|\n",
    "| RandomHorizontalFlip()         | Randomly flip the input horizontally with a 50% chance. |\n",
    "| RandomRotation(10)             | Rotate the input randomly by a degree chosen uniformly from the range [-10, 10]. |\n",
    "| RandomCrop(32, padding=4)      | Crop the input at a random location with padding of 4 and size of 32x32. |\n",
    "| ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2) | Randomly change the brightness, contrast, and saturation of an image. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b)\n",
    "| Data             | Loss | Accuracy |\n",
    "|------------------|------|----------|\n",
    "| Training         | 0.48 | 83.9 %   |\n",
    "| Validation       | 0.48 | 83.9 %   |\n",
    "| Test             | 0.48 | 83.6 %   |\n",
    "\n",
    "![Task 2](./plots/task3_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3c)\n",
    "\n",
    "#### What worked\n",
    "The biggest improvements were seen by increasing the number of trainable parameters in the model, changing the optimizer to Adagrad, and by adding transformations to the images of the training set. \n",
    "In my opinion all of these methods worked because of the following:\n",
    "- increasing the number of layers, it allowed the network to learn more parameters because we were limited with the number of epochs, and the intial network was maybe a bit to small to store all the important information.\n",
    "- optimizer, Adagrad in my opinion performed better because it adapts the learning rate for each parameter based on the past ones, which can prevent the algorithm from overshootign the minimum. From iits use it other areas it has also been shown that it performs better on smaller datasets, since it delivers larger updates to infrequent parameters and smaller updates to frequent ones.\n",
    "- tranformations, due to us tranforming the data, we had \"more\" images to train on, which lead to network capturing the actual pattern in the data that contribute to class predictions, hence increasing the accuracy of the network.\n",
    "\n",
    "#### What didn't \n",
    "- Dropout of 0.2, it didn't seem to improve the accuracy of the network from which we can assume that the weight decay was sufficient to regularize the network.\n",
    "- Replacing the activation function ReLU, we had tested LeakyReLU and SELU as alternative functions. But they didn't seem to perform better so the original activation function was kept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3d)\n",
    "The most significant improvement apart from modifying the network arhitecture (where it is hard to narrow down which exact part contributed the most), was the replacement of SGD with Adagrad. This alone contributed ~3-4% to the accuracy increase of the model predictions.\n",
    "\n",
    "TODO plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3e)\n",
    "The plot is the same as for 3b, since I described the final model which performed best.\n",
    "![Task 2](./plots/task3_plot.png)\n",
    "\n",
    "\n",
    "### Task 3f)\n",
    "\n",
    "For the best model the loss seems to be starting to stagnate, but it isn't quite there yet. I would say that if the model ran for longer we could see this in action, which is probably the result of the overfitting in this specific case. Overall I would say the model performs quite good, since the training and validation accuracies are close to the test one, which means that the model learned actual data patterns and is not overfitting with the help of memorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "We implemented transfer learning with Resnet18. \n",
    "Hyperparameters used:\n",
    "\n",
    "| Hyperparameter | Value          |\n",
    "|----------------|----------------|\n",
    "| optimizer      | Adam Optimizer |\n",
    "| batch size     | 64             |\n",
    "| learning rate  | 5 x $10^{-5}$  |\n",
    "\n",
    "Data transformation and data augmentation used:\n",
    "\n",
    "| Transformation       | Value               |\n",
    "|----------------------|---------------------|\n",
    "| Resize               | (112,112)           |\n",
    "| RandomHorizontalFlip | p=0.5               |\n",
    "| ColorJitter          | brightness=0.5      |\n",
    "| RandomRotation       | degrees=15          |\n",
    "| RandomGrayscale      | p=0.2               |\n",
    "| GaussianBlur         | 3, sigma=(0.1, 2.0) |\n",
    "| Normalize            | (mean, std)         |\n",
    "   \n",
    "\n",
    "Our final test accuracy: **XX%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Task 4](./plots/task4_plot.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
